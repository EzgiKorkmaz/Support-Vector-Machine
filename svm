

import numpy as np
import random, math
from scipy.optimize import minimize
import matplotlib.pyplot as plt
import scipy.linalg

### Let us create our labeled training data from a Gaussian distribution ###

classA = np.concatenate((np.random.randn(10,2) * 0.9 + [1.5,0.5], np.random.randn(10,2)* 0.2 + [-1.5,0.5]))
classB = np.random.randn(20, 2) * 0.3 + [0.0, -0.5]

inputs = np.concatenate((classA, classB))
targets = np.concatenate((np.ones(classA.shape[0]),-np.ones(classB.shape[0])))

N = inputs.shape[0]  #number of rows (samples)

permute = list(range(N))
random.shuffle(permute)
inputs = inputs[permute,:]
targets = targets [permute]

x = inputs


plt.plot ([p[0] for p in classA] , [p[1] for p in classA] , 'b.')
plt.plot ([p[0] for p in classB] , [p[1] for p in classB] , 'r.')

plt.axis('equal')   #force same scale on both axis
plt.savefig('svmplot1.pdf')
plt.show()


####  Let us define different Kernels for different datasets that we are going to use ###


def linear_kernel(x1, x2):
    return np.dot(x1, x2)


def polynomial_kernel(x, y, p=7):
    return (1 + np.dot(x, y)) ** p

def gaussian_kernel(x, y, sigma=0.9):
    return np.exp(-np.linalg.norm(x-y)**2 / (2 * (sigma ** 2)))
